{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.09280742459396751,
  "eval_steps": 500,
  "global_step": 60,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0015467904098994587,
      "grad_norm": 23.401756286621094,
      "learning_rate": 0.0,
      "loss": 5.118,
      "step": 1
    },
    {
      "epoch": 0.0030935808197989174,
      "grad_norm": 22.131683349609375,
      "learning_rate": 4e-05,
      "loss": 4.7696,
      "step": 2
    },
    {
      "epoch": 0.004640371229698376,
      "grad_norm": 17.175020217895508,
      "learning_rate": 8e-05,
      "loss": 4.8961,
      "step": 3
    },
    {
      "epoch": 0.006187161639597835,
      "grad_norm": 11.376545906066895,
      "learning_rate": 0.00012,
      "loss": 4.4568,
      "step": 4
    },
    {
      "epoch": 0.007733952049497293,
      "grad_norm": 3.0440282821655273,
      "learning_rate": 0.00016,
      "loss": 4.4005,
      "step": 5
    },
    {
      "epoch": 0.009280742459396751,
      "grad_norm": 1.7715504169464111,
      "learning_rate": 0.0002,
      "loss": 4.2217,
      "step": 6
    },
    {
      "epoch": 0.01082753286929621,
      "grad_norm": 1.17129647731781,
      "learning_rate": 0.00019636363636363636,
      "loss": 3.7315,
      "step": 7
    },
    {
      "epoch": 0.01237432327919567,
      "grad_norm": 1.8174488544464111,
      "learning_rate": 0.00019272727272727274,
      "loss": 4.1805,
      "step": 8
    },
    {
      "epoch": 0.013921113689095127,
      "grad_norm": 1.4200966358184814,
      "learning_rate": 0.0001890909090909091,
      "loss": 3.9751,
      "step": 9
    },
    {
      "epoch": 0.015467904098994586,
      "grad_norm": 1.5031224489212036,
      "learning_rate": 0.00018545454545454545,
      "loss": 3.6048,
      "step": 10
    },
    {
      "epoch": 0.017014694508894045,
      "grad_norm": 1.2223126888275146,
      "learning_rate": 0.00018181818181818183,
      "loss": 3.9006,
      "step": 11
    },
    {
      "epoch": 0.018561484918793503,
      "grad_norm": 1.9934618473052979,
      "learning_rate": 0.0001781818181818182,
      "loss": 3.7413,
      "step": 12
    },
    {
      "epoch": 0.020108275328692964,
      "grad_norm": 1.8834645748138428,
      "learning_rate": 0.00017454545454545454,
      "loss": 3.747,
      "step": 13
    },
    {
      "epoch": 0.02165506573859242,
      "grad_norm": 1.4269163608551025,
      "learning_rate": 0.0001709090909090909,
      "loss": 3.1036,
      "step": 14
    },
    {
      "epoch": 0.02320185614849188,
      "grad_norm": 1.5926333665847778,
      "learning_rate": 0.00016727272727272728,
      "loss": 3.6379,
      "step": 15
    },
    {
      "epoch": 0.02474864655839134,
      "grad_norm": 2.376450538635254,
      "learning_rate": 0.00016363636363636366,
      "loss": 3.5914,
      "step": 16
    },
    {
      "epoch": 0.026295436968290797,
      "grad_norm": 2.1285042762756348,
      "learning_rate": 0.00016,
      "loss": 3.137,
      "step": 17
    },
    {
      "epoch": 0.027842227378190254,
      "grad_norm": 3.2275195121765137,
      "learning_rate": 0.00015636363636363637,
      "loss": 3.1572,
      "step": 18
    },
    {
      "epoch": 0.029389017788089715,
      "grad_norm": 1.7069400548934937,
      "learning_rate": 0.00015272727272727275,
      "loss": 3.2565,
      "step": 19
    },
    {
      "epoch": 0.030935808197989172,
      "grad_norm": 2.635180950164795,
      "learning_rate": 0.0001490909090909091,
      "loss": 3.2284,
      "step": 20
    },
    {
      "epoch": 0.03248259860788863,
      "grad_norm": 2.9154551029205322,
      "learning_rate": 0.00014545454545454546,
      "loss": 2.9748,
      "step": 21
    },
    {
      "epoch": 0.03402938901778809,
      "grad_norm": 2.71947979927063,
      "learning_rate": 0.00014181818181818184,
      "loss": 3.2593,
      "step": 22
    },
    {
      "epoch": 0.03557617942768755,
      "grad_norm": 2.3403403759002686,
      "learning_rate": 0.0001381818181818182,
      "loss": 3.2505,
      "step": 23
    },
    {
      "epoch": 0.037122969837587005,
      "grad_norm": 2.076951742172241,
      "learning_rate": 0.00013454545454545455,
      "loss": 2.9742,
      "step": 24
    },
    {
      "epoch": 0.038669760247486466,
      "grad_norm": 3.4155654907226562,
      "learning_rate": 0.00013090909090909093,
      "loss": 3.0771,
      "step": 25
    },
    {
      "epoch": 0.04021655065738593,
      "grad_norm": 3.2675940990448,
      "learning_rate": 0.00012727272727272728,
      "loss": 2.6589,
      "step": 26
    },
    {
      "epoch": 0.04176334106728538,
      "grad_norm": 2.234013795852661,
      "learning_rate": 0.00012363636363636364,
      "loss": 2.9475,
      "step": 27
    },
    {
      "epoch": 0.04331013147718484,
      "grad_norm": 2.6257758140563965,
      "learning_rate": 0.00012,
      "loss": 2.6382,
      "step": 28
    },
    {
      "epoch": 0.0448569218870843,
      "grad_norm": 3.2900798320770264,
      "learning_rate": 0.00011636363636363636,
      "loss": 2.4987,
      "step": 29
    },
    {
      "epoch": 0.04640371229698376,
      "grad_norm": 3.2654800415039062,
      "learning_rate": 0.00011272727272727272,
      "loss": 2.6384,
      "step": 30
    },
    {
      "epoch": 0.04795050270688322,
      "grad_norm": 2.3112361431121826,
      "learning_rate": 0.00010909090909090909,
      "loss": 3.0298,
      "step": 31
    },
    {
      "epoch": 0.04949729311678268,
      "grad_norm": 2.5231101512908936,
      "learning_rate": 0.00010545454545454545,
      "loss": 2.9292,
      "step": 32
    },
    {
      "epoch": 0.05104408352668213,
      "grad_norm": 2.852637767791748,
      "learning_rate": 0.00010181818181818181,
      "loss": 2.577,
      "step": 33
    },
    {
      "epoch": 0.05259087393658159,
      "grad_norm": 2.4354286193847656,
      "learning_rate": 9.818181818181818e-05,
      "loss": 2.6612,
      "step": 34
    },
    {
      "epoch": 0.054137664346481054,
      "grad_norm": 2.3932619094848633,
      "learning_rate": 9.454545454545455e-05,
      "loss": 2.521,
      "step": 35
    },
    {
      "epoch": 0.05568445475638051,
      "grad_norm": 2.2516045570373535,
      "learning_rate": 9.090909090909092e-05,
      "loss": 2.0445,
      "step": 36
    },
    {
      "epoch": 0.05723124516627997,
      "grad_norm": 3.4009923934936523,
      "learning_rate": 8.727272727272727e-05,
      "loss": 2.4248,
      "step": 37
    },
    {
      "epoch": 0.05877803557617943,
      "grad_norm": 3.120556116104126,
      "learning_rate": 8.363636363636364e-05,
      "loss": 2.5326,
      "step": 38
    },
    {
      "epoch": 0.060324825986078884,
      "grad_norm": 2.117973804473877,
      "learning_rate": 8e-05,
      "loss": 2.3415,
      "step": 39
    },
    {
      "epoch": 0.061871616395978345,
      "grad_norm": 1.8827604055404663,
      "learning_rate": 7.636363636363637e-05,
      "loss": 2.411,
      "step": 40
    },
    {
      "epoch": 0.0634184068058778,
      "grad_norm": 3.0943262577056885,
      "learning_rate": 7.272727272727273e-05,
      "loss": 2.4432,
      "step": 41
    },
    {
      "epoch": 0.06496519721577726,
      "grad_norm": 3.069180727005005,
      "learning_rate": 6.90909090909091e-05,
      "loss": 2.1281,
      "step": 42
    },
    {
      "epoch": 0.06651198762567673,
      "grad_norm": 3.073017120361328,
      "learning_rate": 6.545454545454546e-05,
      "loss": 2.4523,
      "step": 43
    },
    {
      "epoch": 0.06805877803557618,
      "grad_norm": 1.8617616891860962,
      "learning_rate": 6.181818181818182e-05,
      "loss": 2.0886,
      "step": 44
    },
    {
      "epoch": 0.06960556844547564,
      "grad_norm": 1.8726599216461182,
      "learning_rate": 5.818181818181818e-05,
      "loss": 1.9003,
      "step": 45
    },
    {
      "epoch": 0.0711523588553751,
      "grad_norm": 2.547893762588501,
      "learning_rate": 5.4545454545454546e-05,
      "loss": 2.1981,
      "step": 46
    },
    {
      "epoch": 0.07269914926527456,
      "grad_norm": 1.7593146562576294,
      "learning_rate": 5.090909090909091e-05,
      "loss": 2.1826,
      "step": 47
    },
    {
      "epoch": 0.07424593967517401,
      "grad_norm": 2.0018649101257324,
      "learning_rate": 4.7272727272727275e-05,
      "loss": 2.1243,
      "step": 48
    },
    {
      "epoch": 0.07579273008507348,
      "grad_norm": 1.8333152532577515,
      "learning_rate": 4.3636363636363636e-05,
      "loss": 1.8755,
      "step": 49
    },
    {
      "epoch": 0.07733952049497293,
      "grad_norm": 2.158041000366211,
      "learning_rate": 4e-05,
      "loss": 1.8649,
      "step": 50
    },
    {
      "epoch": 0.07888631090487239,
      "grad_norm": 1.602283000946045,
      "learning_rate": 3.6363636363636364e-05,
      "loss": 2.0092,
      "step": 51
    },
    {
      "epoch": 0.08043310131477185,
      "grad_norm": 3.9358975887298584,
      "learning_rate": 3.272727272727273e-05,
      "loss": 2.0061,
      "step": 52
    },
    {
      "epoch": 0.08197989172467131,
      "grad_norm": 1.5957664251327515,
      "learning_rate": 2.909090909090909e-05,
      "loss": 1.961,
      "step": 53
    },
    {
      "epoch": 0.08352668213457076,
      "grad_norm": 1.8859994411468506,
      "learning_rate": 2.5454545454545454e-05,
      "loss": 2.0024,
      "step": 54
    },
    {
      "epoch": 0.08507347254447023,
      "grad_norm": 2.1933176517486572,
      "learning_rate": 2.1818181818181818e-05,
      "loss": 2.4104,
      "step": 55
    },
    {
      "epoch": 0.08662026295436968,
      "grad_norm": 1.9835777282714844,
      "learning_rate": 1.8181818181818182e-05,
      "loss": 1.6197,
      "step": 56
    },
    {
      "epoch": 0.08816705336426914,
      "grad_norm": 1.84016752243042,
      "learning_rate": 1.4545454545454545e-05,
      "loss": 1.9192,
      "step": 57
    },
    {
      "epoch": 0.0897138437741686,
      "grad_norm": 2.196676731109619,
      "learning_rate": 1.0909090909090909e-05,
      "loss": 1.9081,
      "step": 58
    },
    {
      "epoch": 0.09126063418406806,
      "grad_norm": 2.037656307220459,
      "learning_rate": 7.272727272727272e-06,
      "loss": 2.3043,
      "step": 59
    },
    {
      "epoch": 0.09280742459396751,
      "grad_norm": 2.2655794620513916,
      "learning_rate": 3.636363636363636e-06,
      "loss": 2.3088,
      "step": 60
    }
  ],
  "logging_steps": 1,
  "max_steps": 60,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 758704398925824.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
